import streamlit as st
import cv2
import numpy as np
from PIL import Image
from ultralytics import YOLO
import tempfile
import os
import time
# -------------------------
# é¡µé¢é…ç½®
# -------------------------
st.set_page_config(
    page_title="YOLO éšœç¢ç‰©è¯†åˆ«ç³»ç»Ÿ",
    layout="wide"
)
# test


st.title("ğŸš§ YOLO éšœç¢ç‰©è¯†åˆ«æ¨ç†ç³»ç»Ÿ")
st.markdown("ä»…ç”¨äº **æ¨ç†ï¼ˆInferenceï¼‰**ï¼Œä¸åŒ…å«è®­ç»ƒåŠŸèƒ½")

# -------------------------
# åŠ è½½æ¨¡å‹ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰
# -------------------------
@st.cache_resource
def load_model(weight_path):
    return YOLO(weight_path)

model = load_model("weights/best.pt")

# -------------------------
# ä¾§è¾¹æ ï¼šè¶…å‚æ•°è®¾ç½®
# -------------------------
st.sidebar.header("âš™ï¸ æ¨ç†å‚æ•°è®¾ç½®")



conf = st.sidebar.slider(
    "ç½®ä¿¡åº¦é˜ˆå€¼ (conf)",
    min_value=0.0,
    max_value=1.0,
    step=0.05,
    value=0.25
)

iou = st.sidebar.slider(
    "IoU é˜ˆå€¼ (iou)",
    min_value=0.0,
    max_value=1.0,
    step=0.05,
    value=0.45
)


# è¾“å…¥æºé€‰æ‹©
mode = st.sidebar.radio(
    "è¾“å…¥æº",
    ['å›¾ç‰‡','æ‘„åƒå¤´']
)

# -------------------------
# æ¨ç†é€»è¾‘å›¾ç‰‡
# -------------------------
if mode == 'å›¾ç‰‡':
    imgsz = st.sidebar.slider(
        "è¾“å…¥å›¾ç‰‡å¤§å° (imgsz)",
        min_value=320,
        max_value=1280,
        step=32,
        value=640
    )

    # -------------------------
    # å›¾ç‰‡ä¸Šä¼ 
    # -------------------------
    uploaded_file = st.file_uploader(
        "ğŸ“· ä¸Šä¼ å¾…æ£€æµ‹å›¾ç‰‡",
        type=["jpg", "jpeg", "png"],
        accept_multiple_files=True
    )
    if uploaded_file is not None and st.button("ğŸ” å¼€å§‹æ£€æµ‹"):
        # æ˜¾ç¤ºåŸå›¾
        # image = Image.open(uploaded_file).convert("RGB")
        col1, col2 = st.columns(2)
        for uploaded_file in uploaded_file:
            image = Image.open(uploaded_file).convert('RGB')

            with col1:
                st.subheader("åŸå§‹å›¾ç‰‡")
                st.image(image, use_container_width=True)

            with st.spinner("YOLO æ¨ç†ä¸­..."):
                img_np = np.array(image)

                # RGB -> BGRï¼ˆYOLO / OpenCV ä¹ æƒ¯ï¼‰
                img_np = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)


                # YOLO æ¨ç†
                results = model.predict(
                    source= img_np,
                    imgsz=imgsz,
                    conf=conf,
                    iou=iou,
                    save=False
                )

                # å–ç¬¬ä¸€å¼ ç»“æœ
                result = results[0]
                plotted_img = result.plot()  # BGR ndarray

                # BGR -> RGB
                plotted_img = cv2.cvtColor(plotted_img, cv2.COLOR_BGR2RGB)

                with col2:
                    st.subheader("æ£€æµ‹ç»“æœ")
                    st.image(plotted_img, use_container_width=True)

                # å¯é€‰ï¼šæ˜¾ç¤ºæ£€æµ‹ä¿¡æ¯
                st.subheader("ğŸ“‹ æ£€æµ‹ç»“æœè¯¦æƒ…")
                if result.boxes is not None:
                    for box in result.boxes:
                        cls_id = int(box.cls[0])
                        conf_score = float(box.conf[0])
                        class_name = model.names[cls_id]
                        st.write(f"- **{class_name}** | ç½®ä¿¡åº¦: `{conf_score:.2f}`")
elif mode == 'æ‘„åƒå¤´':

    # è‡ªå·±è°ƒæ•´æ˜¾ç¤ºå¤§å°
    display_width = st.sidebar.slider(
        "æ˜¾ç¤ºç”»é¢å®½åº¦",
        min_value=320,
        max_value=1280,
        step=40,
        value=720,
        key="display_width"
    )

    st.subheader("å®æ—¶æ‘„åƒå¤´æ¨ç†")

    if 'cam_running' not in st.session_state:
        st.session_state.cam_running = False

    col_btn1, col_btn2 = st.columns(2)
    with col_btn1:
        if st.button("å¯åŠ¨æ‘„åƒå¤´", key='start_running'):
            st.session_state.cam_running = True

    with col_btn2:
        if st.button("åœæ­¢æ‘„åƒå¤´" , key='stop_running'):
            st.session_state.cam_running = False

    frame_placeholder = st.empty()

    if st.session_state.cam_running:
        cap = cv2.VideoCapture(0)
        # è®¾ç½®é•œå¤´é‡‡é›†çš„åˆ†è¾¨ç‡
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)

        if not cap.isOpened():
            st.error("æ— æ³•æ‰“å¼€æ‘„åƒ")
        else:
            while st.session_state.cam_running:
                start_time = time.time()

                ret, frame = cap.read()
                if not ret:
                    st.warning("æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                    break

                results = model.predict(
                    source=frame,
                    conf=conf,
                    iou=iou,
                    stream=False,
                    verbose=False
                )
                # ç»˜åˆ¶FPS
                end_time = time.time()
                fps = 1 / (end_time - start_time)
                st.caption(f"FPS: {fps:.2f}")
                # ç»˜åˆ¶ç»“æœ
                result = results[0]
                plotted_frame = result.plot()
                # åœ¨å›¾åƒä¸Šæ˜¾ç¤ºFPS
                cv2.putText(
                    plotted_frame,
                    f"FPS: {fps:.2f}",
                    (20,40),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    1,
                    (0,255,0),
                    2
                )
                plotted_frame = cv2.cvtColor(plotted_frame, cv2.COLOR_BGR2RGB)

                frame_placeholder.image(
                    plotted_frame,
                    channels='RGB',
                    # use_container_width=True
                    width=display_width
                )
            cap.release()


